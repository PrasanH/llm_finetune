{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6fbcc31-7204-4b79-874a-f23300aa42d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch                                  # Pytorch\n",
    "!pip install -q transformers datasets                  # Comes from HuggingFace\n",
    "!pip install -q bitsandbytes                           # For quantization from HuggingFace\n",
    "!pip install -q peft                                   # Parameter-efficient Fine-tuning from HuggingFace\n",
    "!pip install -q trl                                    # For supervised fine-tuning for LLMs from HuggingFace\n",
    "!pip install -q accelerate        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59acf04d-7ede-420c-a1ad-38aab4cbd75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "my_hf_key= os.getenv('HF_KEY')\n",
    "\n",
    "login(token= my_hf_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e640fdc-f60c-4382-813c-0e3be455d8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3015, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset_B_complete = pd.read_csv(\"syn_data_3000.csv\", encoding='utf-8')\n",
    "print(dataset_B_complete.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db7ca46a-ada8-47cf-995c-5a4e513bd720",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B = dataset_B_complete.sample(n=2000, random_state=42)  #we will select randomly 2000 examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e14399b-f479-424d-9c79-60f441a232d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>German</th>\n",
       "      <th>French</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Ich bin froh, dass ich einen guten Arbeitsplat...</td>\n",
       "      <td>Je suis heureux d'avoir trouvé un bon emploi a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683</th>\n",
       "      <td>Der Lehrer erklärt die Materie sehr gut und ma...</td>\n",
       "      <td>L'enseignant explique la matière très bien et ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Meine Freunde und ich unterstützen uns gegense...</td>\n",
       "      <td>Mes amis et moi nous soutenons mutuellement da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>Wenn ich auf Reisen bin, probiere ich immer di...</td>\n",
       "      <td>Quand je suis en voyage, j'essaie toujours la ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>Am Ende zählt nicht nur der Erfolg, sondern au...</td>\n",
       "      <td>À la fin, ce ne sont pas seulement les succès ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 German  \\\n",
       "63    Ich bin froh, dass ich einen guten Arbeitsplat...   \n",
       "2683  Der Lehrer erklärt die Materie sehr gut und ma...   \n",
       "102   Meine Freunde und ich unterstützen uns gegense...   \n",
       "2691  Wenn ich auf Reisen bin, probiere ich immer di...   \n",
       "416   Am Ende zählt nicht nur der Erfolg, sondern au...   \n",
       "\n",
       "                                                 French  \n",
       "63    Je suis heureux d'avoir trouvé un bon emploi a...  \n",
       "2683  L'enseignant explique la matière très bien et ...  \n",
       "102   Mes amis et moi nous soutenons mutuellement da...  \n",
       "2691  Quand je suis en voyage, j'essaie toujours la ...  \n",
       "416   À la fin, ce ne sont pas seulement les succès ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_B.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "809deadc-c14b-4d8a-a663-9daf576f322a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "260e6ac1-d2e3-4e5c-9d72-8a2c9bc35b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B.to_csv('df_B.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795438da-277e-4060-a867-a1b011653183",
   "metadata": {},
   "source": [
    "We will use all these examples (from dataset B) for training. But we will split 10% of them for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "752b4b8d-c730-4a8b-9747-ce423756c163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items in training and validation  are: 1800 and  200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, validation_data = train_test_split(df_B, test_size=0.1, random_state=42)\n",
    "print(f\"items in training and validation  are: {len(train_data)} and  {len(validation_data)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f70aab1-b626-4e81-8f4c-73bdb8950af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert the DataFrames into a Dataset\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "validation_dataset = Dataset.from_pandas(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f78f5d7-f561-4160-bea2-e71cfb9aa9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['German', 'French', '__index_level_0__'],\n",
       "    num_rows: 1800\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "094a6162-e2f0-42ef-a05e-7e0e73a10757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_instruction(german_input, french_trans):\n",
    "    return f\"\"\"### Instruction:\n",
    "Translate to French. Do not add anything else.\n",
    "\n",
    "### Input German Sentence:\n",
    "{german_input.strip()}\n",
    "\n",
    "### French Translation:\n",
    "{french_trans.strip()}<|endoftext|>\"\"\" \n",
    "#EOS token for Qwen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2a25fbf-bf49-4bc6-a343-212588945beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that converts a dataset row into the corresponding prompt format\n",
    "def convert_to_instruction_format(data_point):\n",
    "    return {\n",
    "        \"text\": format_instruction(data_point[\"German\"], data_point[\"French\"])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd30e822-25fa-4ec9-a505-bab290dc1538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each row in the dataset\n",
    "def process_dataset(data):\n",
    "    return data.map(\n",
    "        convert_to_instruction_format\n",
    "        ).remove_columns(['German', 'French', '__index_level_0__']) #removing unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b5cccee-4978-4cd0-b30a-4046c1d56498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df326aaeb8349b7a3414e65366a8c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6cf793dfb5749ecaf60c672a1eb72a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = process_dataset(train_dataset)\n",
    "validation_data = process_dataset(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f84c7f1-db4a-44b7-8a30-f5f9148a4460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 1800\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117a8504-e958-4839-b2ae-c818420a0029",
   "metadata": {},
   "source": [
    "#### Load the model and finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "502a8576-f647-4944-998f-d440fe41f53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\",device_map = \"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "629d6a4f-4046-4808-872b-44d2fccc112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the padding token to be the same as the end-of-sequence token.\n",
    "\n",
    "# Padding ensures all sequences in a batch are of equal length.\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Specify that padding should be applied to the right side of the sequences.\n",
    "# This is the standard behavior for causal language models. Causal models, predict the next token in a sequence using only the preceding tokens.\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0d4e626-32ff-4a96-a4f2-4d0c40b374c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary PEFT objects for preparing the model for LoRA training\n",
    "from peft import  LoraConfig, get_peft_model\n",
    "\n",
    "\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "\n",
    "#model = prepare_model_for_kbit_training(model)  \n",
    "#Use only if loading a quantized model-includes float conversions to help stabilize training\n",
    "\n",
    "# Set up LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=16,                                                       # The rank (dimensions) of the LoRA matrices A and B\n",
    "    lora_alpha=64,                                              # Scales the product of matrices AB [W_new = W_old + (A * B) * α]\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],    # Apply LoRA to the attention matrices\n",
    "    lora_dropout=0.1,                                           # Dropout rate to reduce overfitting\n",
    "    bias=\"none\",                                                # Do not train the bias parameter\n",
    "    task_type=\"CAUSAL_LM\"                                       # Task type for autoregressive text generation\n",
    ")\n",
    "\n",
    "# Get the model with unfrozen LoRA layers applied\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "385693c4-fae0-446b-86b1-8e149200832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTConfig\n",
    "\n",
    "# Set up the training hyperparameters\n",
    "training_arguments = SFTConfig(\n",
    "    fp16=True,                           # Use 16-bit precision for training computations (optimizer states, gradients)\n",
    "    dataset_text_field=\"text\",           # Specify the text field in the dataset for training\n",
    "    max_seq_length=128,                 # Set the maximum sequence length for the training data\n",
    "\n",
    "    # Batch-related parameters\n",
    "    per_device_train_batch_size=4,       # Batch size per device during training\n",
    "\n",
    "    # Optimizer-related parameters\n",
    "    optim=\"paged_adamw_32bit\",           # Use the paged AdamW optimizer, optimized for 32-bit GPUs\n",
    "    learning_rate=1e-4,                  # Set the learning rate for training\n",
    "\n",
    "    # Epochs and saving configuration\n",
    "    num_train_epochs=4,                  # Number of training epochs (more epochs generally lead to better results)\n",
    "    save_strategy=\"epoch\",               # Save the model after each epoch\n",
    "    output_dir=\"./epoch-finetuned\",      # Directory to save the fine-tuned model\n",
    "\n",
    "    # Validation-related parameters\n",
    "    eval_strategy=\"steps\",               # Evaluation strategy, performed at specified steps\n",
    "    eval_steps=0.2,                      # Evaluate after 20% of the training steps\n",
    "\n",
    "    # Logging-related parameters\n",
    "    report_to=\"none\",                    # Disable reporting to external tools\n",
    "    logging_dir=\"./logs\",                # Directory to save the training logs\n",
    "    logging_steps=20,                    # Number of steps between each log entry\n",
    "    seed=42,                             # Set a random seed for reproducibility\n",
    ")\n",
    "\n",
    "# Enable gradient checkpointing to save memory and recompute during backpropagation\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# Disable attention cache during training; it should be enabled during inference\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc78f7d0-2d21-49ac-8e40-9d931d3a7e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59052/2900952727.py:5: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SFTTrainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808a544b534f47e992611405fb44928e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594e4b7321f94c49acd17d484ea955b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4337e82d45c94b0a94551c3f9a515532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabd41dcd9d54cc99330677157a25bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9d2cefcf0247d1a2ebe1c03cf9eeab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting eval dataset to ChatML:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02979e34c70e4c4287231018519f462e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94be6584cdaa406592e563d8211d8033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d7b97738004f96a4db4dce5ef444d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# Import the SFTTrainer from HuggingFace TRL library\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = SFTTrainer(\n",
    "    # Assign the model and tokenizer\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "\n",
    "    # Provide the training and validation datasets\n",
    "    train_dataset= train_data,\n",
    "    eval_dataset=validation_data,\n",
    "\n",
    "    # Pass the LoRA configuration\n",
    "    peft_config=lora_config,\n",
    "\n",
    "    # Set the training hyperparameters\n",
    "    args=training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65c2806e-7b86-4369-a6c6-ee68f5abca00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1800' max='1800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1800/1800 08:33, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.589053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.513800</td>\n",
       "      <td>0.557075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.484600</td>\n",
       "      <td>0.537337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.451100</td>\n",
       "      <td>0.530814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.471600</td>\n",
       "      <td>0.527444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1800, training_loss=0.5252584155400594, metrics={'train_runtime': 514.2178, 'train_samples_per_second': 14.002, 'train_steps_per_second': 3.5, 'total_flos': 3777190135418880.0, 'train_loss': 0.5252584155400594})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the training process \n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1490bcc9-7144-4cd7-a02e-ac616e72051e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24M\n",
      "-rwxr--r-- 1 prasanna99h prasanna99h 5.0K Mar 12 15:12 README.md\n",
      "-rwxr--r-- 1 prasanna99h prasanna99h  722 Mar 12 15:12 adapter_config.json\n",
      "-rwxr--r-- 1 prasanna99h prasanna99h 8.4M Mar 12 15:12 adapter_model.safetensors\n",
      "-rwxr--r-- 1 prasanna99h prasanna99h  605 Mar 12 15:12 added_tokens.json\n",
      "-rwxr--r-- 1 prasanna99h prasanna99h 1.6M Mar 12 15:12 merges.txt\n",
      "-rwxr--r-- 1 prasanna99h prasanna99h  496 Mar 12 15:12 special_tokens_map.json\n",
      "-rwxr--r-- 1 prasanna99h prasanna99h  11M Mar 12 15:12 tokenizer.json\n",
      "-rwxr--r-- 1 prasanna99h prasanna99h 7.2K Mar 12 15:12 tokenizer_config.json\n",
      "-rwxr--r-- 1 prasanna99h prasanna99h 2.7M Mar 12 15:12 vocab.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Define the save path for the fine-tuned model on Colab\n",
    "peft_model_path = \"./fine-tuned-qwen2.5-1.5b-instruct-step7\"\n",
    "\n",
    "# Save the trained model\n",
    "trainer.model.save_pretrained(peft_model_path)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(peft_model_path)\n",
    "\n",
    "# List the saved files\n",
    "!ls -lh {peft_model_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cb594f-f2fb-4108-95c4-549302aa77b4",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "#### Before loading the tuned model, lets move back the original model to cpu. We can also delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0119f75c-89e2-4854-990c-1fc42043c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model.to(\"cpu\")  # Move the existing model to CPU\n",
    "\n",
    "torch.cuda.empty_cache()  # Clear GPU cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82e7a7b8-3df1-4139-ba1e-6003bf6a30e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loading a PEFT model, we need to use a special object for CausalLM from PEFT\n",
    "# instead of the regular HuggingFace object.\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load the fine-tuned model\n",
    "peft_model_path = \"./fine-tuned-qwen2.5-1.5b-instruct-step7\"\n",
    "tuned_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    peft_model_path,\n",
    "      \n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tuned_model.to(device)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_path)\n",
    "\n",
    "# Set the padding token to be the same as the end-of-sequence token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Specify that padding should be added to the right side of the sequences\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# Enable attention cache during inference\n",
    "tuned_model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50671a0-ac4f-4cd5-9422-5d39312159ad",
   "metadata": {},
   "source": [
    "Now we load dataset A and generate the test set using same random seed as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16319b61-9eb7-4052-a062-285cc743c343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of items: 200\n"
     ]
    }
   ],
   "source": [
    "test_A = pd.read_csv(\"deliverables/df_csv/test_A.csv\", encoding='utf-8')\n",
    "print(f'num of items: {len(test_A)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7876e63d-30d8-4405-bb8a-fc5a3303b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_tuned_model(prompt):\n",
    "  inputs = tokenizer (prompt, return_tensors=\"pt\")\n",
    "  inputs = inputs.to(tuned_model.device)\n",
    "\n",
    "  output_tokens = tuned_model.generate(\n",
    "    inputs.input_ids,\n",
    "    max_new_tokens=40,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    do_sample=True,\n",
    ")[0]\n",
    "  output = tokenizer.decode(output_tokens, skip_special_tokens=True)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00d0e402-9de4-4807-9933-cc8c611cce6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating: 100%|██████████| 200/200 [05:19<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected translations for 200 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "translation_list=[]\n",
    "for row in tqdm(range(len(test_A)),desc=\"Translating\"):\n",
    "\n",
    "  my_prompt = f\"\"\"### Input German Sentence:\n",
    "{test_A.iloc[row, 0].strip()}\n",
    "\n",
    "### French Translation:\n",
    "\n",
    "\"\"\"\n",
    "  translation = get_output_tuned_model(my_prompt)\n",
    "  translation = translation.replace(my_prompt, \"\")\n",
    "  translation_list.append(translation)\n",
    "print(f'collected translations for {len(translation_list)} items.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72f0ece0-1334-48c4-8dbb-361365cfef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('translations_test_C_qwen.txt', 'w') as f:\n",
    "    for item in translation_list:\n",
    "        f.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c12c17f8-4bd2-4bcb-81b4-b91be11d7954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate         ##metric for evaulation, HF library\n",
    "def calculate_bleu_score(prediction, reference):\n",
    "\n",
    "\n",
    "  #reference = [[reference.lower().split()]]\n",
    "  #prediction = [prediction.lower().split()]\n",
    "  prediction = [prediction]\n",
    "  reference = [[reference]]\n",
    "\n",
    "  bleu = evaluate.load(\"bleu\")\n",
    "  score = bleu.compute(predictions= prediction,references=reference)\n",
    "\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5992485-0aaf-48d1-86e1-b560ae9ae22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_evaluation_df(translation_list, actual_df):\n",
    "  \"\"\"\n",
    "  translation_list is a list of translations (has just the target language sentences) from the llm to be evaluated\n",
    "  actual_df : a dataframe containing the actual sentence and its translation\n",
    "  \"\"\"\n",
    "  evaluation =[]\n",
    "  evaluation_df = pd.DataFrame(columns=[\n",
    "    'Actual', \n",
    "    'Reference', \n",
    "    'Prediction', \n",
    "    'BLEU Score', \n",
    "    'Precisions', \n",
    "    'Brevity Penalty', \n",
    "    'Length Ratio', \n",
    "    'Translation Length', \n",
    "    'Reference Length'\n",
    "])\n",
    "  for i in tqdm(range(len(translation_list))):\n",
    "    actual = actual_df.iloc[i,0]\n",
    "    reference = actual_df.iloc[i,1]\n",
    "    prediction = translation_list[i]\n",
    "    score = calculate_bleu_score(prediction, reference)\n",
    "\n",
    "    evaluation_data = {\n",
    "        'Actual': actual,\n",
    "        'Reference': reference,\n",
    "        'Prediction': prediction,\n",
    "        'BLEU Score': score['bleu'],\n",
    "        'Precisions': score['precisions'],\n",
    "        'Brevity Penalty': score['brevity_penalty'],\n",
    "        'Length Ratio': score['length_ratio'],\n",
    "        'Translation Length': score['translation_length'],\n",
    "        'Reference Length': score['reference_length']\n",
    "    }\n",
    "    evaluation.append(evaluation_data)\n",
    "    \n",
    "    # Concatenate all evaluation data into the DataFrame\n",
    "    evaluation_df_concat = pd.concat([evaluation_df, pd.DataFrame(evaluation)], ignore_index=True)\n",
    "\n",
    "  return evaluation_df_concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ecab6c2-bf81-4bdd-84fa-4c1634564815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_59052/2784772388.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  evaluation_df_concat = pd.concat([evaluation_df, pd.DataFrame(evaluation)], ignore_index=True)\n",
      "100%|██████████| 200/200 [01:17<00:00,  2.58it/s]\n"
     ]
    }
   ],
   "source": [
    "result_df = get_evaluation_df(translation_list, test_A )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb9f0bed-df0b-400c-bb75-67ff5a2bdcfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 9)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b71450d-6540-482d-9da4-881c552ccde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average bleu score is 0.013786942341864698\n"
     ]
    }
   ],
   "source": [
    "print(f'average bleu score is {result_df[\"BLEU Score\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29039bfd-4fd4-4642-834a-9b8582de625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('results_df_C_step8.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e524fe0-f8c2-4ad0-90b6-7e97ee5e873a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
